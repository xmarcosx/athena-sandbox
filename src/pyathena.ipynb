{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Athena Samples\n",
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from pyathena import connect\n",
    "from urllib.parse import quote_plus\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "aws_key = os.environ['AWS_KEY']\n",
    "aws_secret = os.environ['AWS_SECRET']\n",
    "\n",
    "bucket_name = os.environ['S3_BUCKET_NAME']\n",
    "staging_bucket_name = os.environ['S3_STAGING_BUCKET_NAME']\n",
    "region = os.environ['REGION']\n",
    "schema_name='marcosraw'\n",
    "s3_staging_dir=f's3://{staging_bucket_name}/pyathena-staging/'\n",
    "s3_dir=f's3://{bucket_name}/'\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Query Athena"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "connection = connect(aws_access_key_id=aws_key,\n",
    "                 aws_secret_access_key=aws_secret,\n",
    "                 schema_name=schema_name,\n",
    "                 s3_staging_dir=s3_staging_dir,\n",
    "                 region_name=region\n",
    "        )\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM studentlocaleducationagencydim\", connection)\n",
    "\n",
    "df[['studentkey', 'studentlastname', 'studentfirstname']].head()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load into Athena"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "conn_str = \"awsathena+rest://{aws_access_key_id}:{aws_secret_access_key}@athena.{region_name}.amazonaws.com:443/\"\\\n",
    "           \"{schema_name}?s3_staging_dir={s3_staging_dir}&s3_dir={s3_dir}&compression=snappy\"\n",
    "\n",
    "engine = create_engine(conn_str.format(\n",
    "    aws_access_key_id=aws_key,\n",
    "    aws_secret_access_key=aws_secret,\n",
    "    region_name=region,\n",
    "    schema_name=schema_name,\n",
    "    s3_staging_dir=quote_plus(s3_staging_dir),\n",
    "    s3_dir=quote_plus(f'{s3_dir}')))\n",
    "\n",
    "df = pd.DataFrame({\"a\": [1, 2, 3, 4, 5]})\n",
    "df.to_sql(\"sampledb\", engine, schema=schema_name, index=False, if_exists=\"replace\", method=\"multi\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}